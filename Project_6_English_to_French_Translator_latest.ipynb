{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Project -6  English to French Translator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "WSNzbrbu1Lz_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<H2> Project -6 English to French Translator </H2>\n"
      ]
    },
    {
      "metadata": {
        "id": "xpmN9LeC1qv-",
        "colab_type": "code",
        "outputId": "14577387-dee3-4e2a-8111-377319c99e2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 24.6MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 2.3MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 3.4MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 2.2MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 2.7MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 3.2MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 3.6MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 4.1MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 4.6MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 3.5MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 3.6MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 5.0MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 5.0MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 9.3MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 9.3MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 9.4MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 9.4MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 9.3MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 9.2MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 35.5MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 10.6MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 10.5MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 10.7MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 10.6MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 10.6MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 10.4MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 10.6MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 10.7MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 10.8MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 11.3MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 48.2MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 48.0MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 49.8MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 47.1MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 45.9MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 49.2MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 48.9MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 49.9MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 12.4MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 12.4MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 12.4MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 12.5MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 12.3MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 12.4MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 12.5MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 12.5MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 12.6MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 12.5MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 51.6MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 47.1MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 47.2MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 46.7MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 48.7MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 51.6MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 50.8MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 49.4MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 48.9MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 49.5MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 49.1MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 53.8MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 50.9MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 50.6MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 50.0MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 51.1MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 41.6MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 41.5MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 42.0MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 41.5MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 40.6MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 40.2MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 41.8MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 42.3MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 42.5MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 20.8MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 22.9MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 22.8MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 22.4MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 22.4MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 22.7MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 22.9MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 22.8MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 22.6MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 22.5MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 45.7MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 45.7MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 47.0MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 49.8MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 50.3MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 51.1MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 51.1MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 50.7MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 51.1MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 51.2MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 56.6MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 57.1MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 56.4MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 20.6MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0jyKpur-1L0H",
        "colab_type": "code",
        "outputId": "34422be0-1d72-4854-a169-3c66569785ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, RepeatVector, TimeDistributed\n",
        "import numpy as np\n",
        "\n",
        "from pickle import load\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "U1jlgwXI11Bd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6bG498sA5Jxk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file1 = drive.CreateFile({'id':'1ERbtIfAlEO_2g2EY6giS-r49tFSdjJIM'})\n",
        "file1.GetContentFile('small_vocab_fr.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XM-olQW85c3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file2 = drive.CreateFile({'id':'1vn4DFiEV6boyB_GB52OswDAW6GC8oGQC'})\n",
        "file2.GetContentFile('small_vocab_en.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H-8gsZDu5nM2",
        "colab_type": "code",
        "outputId": "5c1984ea-3667-4294-d40e-0b7000d850fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  sample_data  small_vocab_en.txt  small_vocab_fr.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6XrVAUK91L05",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<H3> Loading both English and French files</H3>"
      ]
    },
    {
      "metadata": {
        "id": "H_v-Aabi1L0-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eng_sent = open('small_vocab_en.txt', encoding='utf-8').read().split('\\n')\n",
        "fra_sent = open('small_vocab_fr.txt', encoding='utf-8').read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pcuhGbWm1L1V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<H4> Length of English and French file </H4>"
      ]
    },
    {
      "metadata": {
        "id": "yZPyCFuv1L1c",
        "colab_type": "code",
        "outputId": "60fe18c0-196b-414d-cdd0-8bd9498e2382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(eng_sent)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137861"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "_R7Tgr7r1L15",
        "colab_type": "code",
        "outputId": "56900e18-0c0c-48e8-d3a2-16224641d3da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(fra_sent)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137861"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "GUbMdXAc1L2K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<H3> Get unique number of characters in both English and French files </H3>"
      ]
    },
    {
      "metadata": {
        "id": "lAuBAVI61L2R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eng_chars = []\n",
        "fra_chars = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WIMGMPG61L2e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nb_samples = len(fra_sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dveQGiXg1L2s",
        "colab_type": "code",
        "outputId": "33eb93bd-bd10-4d68-8911-94bab40d8fb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "nb_samples"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137861"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "Z9cnUpQR1L3G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for line in range(nb_samples):\n",
        "    eng_line = eng_sent[line]\n",
        "    fra_line = fra_sent[line]\n",
        "    for ch in eng_line:\n",
        "        if (ch not in eng_chars):\n",
        "            eng_chars.append(ch)\n",
        "    for ch in fra_line:\n",
        "        if (ch not in fra_chars):\n",
        "            fra_chars.append(ch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z1ZuXBsB1L37",
        "colab_type": "code",
        "outputId": "e742c91d-d139-4c2c-c30c-c3939f5da65c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(fra_chars) # unique french characters"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "mdoT8DUb1L4M",
        "colab_type": "code",
        "outputId": "f1d08f9d-87fb-44ca-d1d1-06adbc52dcc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(eng_chars) # unique English characters"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "y8g1fCdI1L4n",
        "colab_type": "code",
        "outputId": "a16048b5-1237-42b7-ec76-992b3cb94c0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "fra_sent[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "b61wHSep1L5K",
        "colab_type": "code",
        "outputId": "430633ff-bd35-44ff-eb0e-676b10083296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "eng_sent[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'new jersey is sometimes quiet during autumn , and it is snowy in april .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "k8Qhaqr1EcDo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a Dictionary where it will map every index to a english character and a reverse dictionary to map every english  character to a index."
      ]
    },
    {
      "metadata": {
        "id": "6B2JFRoq1L5i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dictionary to index each english character - key is index and value is english character\n",
        "eng_index_to_char_dict = {}\n",
        "# dictionary to get english character given its index - key is english character and value is index\n",
        "eng_char_to_index_dict = {}\n",
        "\n",
        "for k, v in enumerate(eng_chars):\n",
        "    eng_index_to_char_dict[k] = v\n",
        "    eng_char_to_index_dict[v] = k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K4Z6Yr9QEw8K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a Dictionary where it will map every index to a french character and a reverse dictionary to map every french character to a index "
      ]
    },
    {
      "metadata": {
        "id": "pkvUPRHy1L5w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dictionary to index each french character - key is index and value is french character\n",
        "fra_index_to_char_dict = {}\n",
        "\n",
        "# dictionary to get french character given its index - key is french character and value is index\n",
        "fra_char_to_index_dict = {}\n",
        "\n",
        "for k, v in enumerate(fra_chars):\n",
        "    fra_index_to_char_dict[k] = v\n",
        "    fra_char_to_index_dict[v] = k\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NRrTaP541L5_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Length of each  maximum sentences in both english and french and get the maximum length\n",
        "max_len_eng_sent = max([len(line) for line in eng_sent])\n",
        "max_len_fra_sent = max([len(line) for line in fra_sent])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zMgj8Eaq1L6Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fra_chars = sorted(fra_chars)\n",
        "eng_chars = sorted(eng_chars)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jh0-EiuO1L6n",
        "colab_type": "code",
        "outputId": "372abfd8-84c0-4609-ceed-4a567417df28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(max_len_eng_sent)\n",
        "print(max_len_fra_sent)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102\n",
            "114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1C1NUD0K1L62",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenized_eng_sentences = np.zeros(shape = (nb_samples,max_len_eng_sent,len(eng_chars)), dtype='float32')\n",
        "tokenized_fra_sentences = np.zeros(shape = (nb_samples,max_len_fra_sent,len(fra_chars)), dtype='float32')\n",
        "target_data = np.zeros((nb_samples, max_len_fra_sent, len(fra_chars)),dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fW8XHzRd1L7D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Vectorize the english and french sentences\n",
        "#Replace characters with the corresponding numbers from the dictionary and create a 3 dimensional vectors \n",
        "\n",
        "for i in range(nb_samples):\n",
        "    for k,ch in enumerate(eng_sent[i]):\n",
        "        tokenized_eng_sentences[i,k,eng_char_to_index_dict[ch]] = 1\n",
        "        \n",
        "    for k,ch in enumerate(fra_sent[i]):\n",
        "        tokenized_fra_sentences[i,k,fra_char_to_index_dict[ch]] = 1\n",
        "\n",
        "        # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
        "        if k > 0:\n",
        "            target_data[i,k-1,fra_char_to_index_dict[ch]] = 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JVc7DkW_1L7S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Encoder model\n",
        "\n",
        "encoder_input = Input(shape=(None,len(eng_chars)))\n",
        "encoder_LSTM = LSTM(256,return_state = True)\n",
        "encoder_outputs, encoder_h, encoder_c = encoder_LSTM (encoder_input)\n",
        "encoder_states = [encoder_h, encoder_c]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0XxPbAC51L7e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Decoder model\n",
        "\n",
        "decoder_input = Input(shape=(None,len(fra_chars)))\n",
        "decoder_LSTM = LSTM(256,return_sequences=True, return_state = True)\n",
        "decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
        "decoder_dense = Dense(len(fra_chars),activation='softmax')\n",
        "decoder_out = decoder_dense (decoder_out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eEAtvi0a1L7s",
        "colab_type": "code",
        "outputId": "55b0dd1a-e900-4a2b-ec19-b62cddc948a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1203
        }
      },
      "cell_type": "code",
      "source": [
        "#Model creation and running and training \n",
        "model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out])\n",
        "\n",
        "# Run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.fit(x=[tokenized_eng_sentences,tokenized_fra_sentences], \n",
        "          y=target_data,\n",
        "          batch_size=64,\n",
        "          epochs=30,\n",
        "          validation_split=0.2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 110288 samples, validate on 27573 samples\n",
            "Epoch 1/30\n",
            "110288/110288 [==============================] - 586s 5ms/step - loss: 0.3301 - val_loss: 0.1410\n",
            "Epoch 2/30\n",
            "110288/110288 [==============================] - 579s 5ms/step - loss: 0.1204 - val_loss: 0.1140\n",
            "Epoch 3/30\n",
            "110288/110288 [==============================] - 588s 5ms/step - loss: 0.1050 - val_loss: 0.1034\n",
            "Epoch 4/30\n",
            "110288/110288 [==============================] - 591s 5ms/step - loss: 0.0958 - val_loss: 0.0953\n",
            "Epoch 5/30\n",
            "110288/110288 [==============================] - 588s 5ms/step - loss: 0.0880 - val_loss: 0.0878\n",
            "Epoch 6/30\n",
            "110288/110288 [==============================] - 593s 5ms/step - loss: 0.0789 - val_loss: 0.0766\n",
            "Epoch 7/30\n",
            "110288/110288 [==============================] - 591s 5ms/step - loss: 0.0696 - val_loss: 0.0692\n",
            "Epoch 8/30\n",
            "110288/110288 [==============================] - 588s 5ms/step - loss: 0.0614 - val_loss: 0.0607\n",
            "Epoch 9/30\n",
            "110288/110288 [==============================] - 584s 5ms/step - loss: 0.0562 - val_loss: 0.0552\n",
            "Epoch 10/30\n",
            "110288/110288 [==============================] - 572s 5ms/step - loss: 0.0525 - val_loss: 0.0535\n",
            "Epoch 11/30\n",
            "   960/110288 [..............................] - ETA: 8:49 - loss: 0.0506"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-5ac79f16d250>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           validation_split=0.2)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qY2KwnznFLR3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Stopped the model for 10 epochs as it was taking time."
      ]
    },
    {
      "metadata": {
        "id": "2CeeOno21L78",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Inference models for testing\n",
        "\n",
        "# Encoder inference model\n",
        "encoder_model_inf = Model(encoder_input, encoder_states)\n",
        "\n",
        "# Decoder inference model\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, \n",
        "                                                 initial_state=decoder_input_states)\n",
        "\n",
        "decoder_states = [decoder_h , decoder_c]\n",
        "\n",
        "decoder_out = decoder_dense(decoder_out)\n",
        "\n",
        "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n",
        "                          outputs=[decoder_out] + decoder_states )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HPnXKwWR1L8O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode_seq(inp_seq):\n",
        "    \n",
        "    # Initial states value is coming from the encoder \n",
        "    states_val = encoder_model_inf.predict(inp_seq)\n",
        "    \n",
        "    target_seq = np.zeros((1, 1, len(fra_chars)))\n",
        "    #target_seq[0, 0, fra_char_to_index_dict['\\t']] = 1\n",
        "    \n",
        "    translated_sent = ''\n",
        "    stop_condition = False\n",
        "    \n",
        "    while not stop_condition:\n",
        "        \n",
        "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
        "        \n",
        "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
        "        sampled_fra_char = fra_index_to_char_dict[max_val_index]\n",
        "        translated_sent += sampled_fra_char\n",
        "        \n",
        "        if ( (sampled_fra_char == '\\n') or (len(translated_sent) > max_len_fra_sent)) :\n",
        "            stop_condition = True\n",
        "        \n",
        "        target_seq = np.zeros((1, 1, len(fra_chars)))\n",
        "        target_seq[0, 0, max_val_index] = 1\n",
        "        \n",
        "        states_val = [decoder_h, decoder_c]\n",
        "        \n",
        "    return translated_sent\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pt9RMpVy1L8u",
        "colab_type": "code",
        "outputId": "725a678a-06dd-4146-83eb-6c084894905c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "for seq_index in range(10):\n",
        "    inp_seq = tokenized_eng_sentences[seq_index:seq_index+1]\n",
        "    translated_sent = decode_seq(inp_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', eng_sent[seq_index])\n",
        "    print('Decoded sentence:', translated_sent)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
            "Decoded sentence: a is est parfois calme au mois de mai , mais il est parfois agréable en juin .t mais en été est le citrons .t les c\n",
            "-\n",
            "Input sentence: the united states is usually chilly during july , and it is usually freezing in november .\n",
            "Decoded sentence: es états-unis est généralement froid en juin , et il est généralement froid en juin .t mais .ent est jamais chaud e\n",
            "-\n",
            "Input sentence: california is usually quiet during march , and it is usually hot in june .\n",
            "Decoded sentence: a france est généralement calme en juin , et il est jamais beau en juin .tmois .imé .et .en .occhaux .octe au moin \n",
            "-\n",
            "Input sentence: the united states is sometimes mild during june , and it is cold in september .\n",
            "Decoded sentence: es états-unis est parfois doux en juin , et il est occupé en juin .tmbie ..cté .occha ent l'ocitre ..tie .nis aimpi\n",
            "-\n",
            "Input sentence: your least liked fruit is the grape , but my least liked is the apple .\n",
            "Decoded sentence: on moins aimé des fruits est le pamplemousse , mais son moins aimé est la poire ...tis leur moins aimé est le citro\n",
            "-\n",
            "Input sentence: his favorite fruit is the orange , but my favorite is the grape .\n",
            "Decoded sentence: ot fruit préféré est l'orange , mais son préféré est la banane ..tis votre moins préféré est le citron ..t son moin\n",
            "-\n",
            "Input sentence: paris is relaxing during december , but it is usually chilly in july .\n",
            "Decoded sentence: a france est le gel en juin , mais il est généralement merveilleux en juin .t mais .ent est jamais chaud en juillet\n",
            "-\n",
            "Input sentence: new jersey is busy during spring , and it is never hot in march .\n",
            "Decoded sentence: a france est généralement calme en juin , et il est agréable en juin .t mais .ent est jamais chaud en juillet . .t \n",
            "-\n",
            "Input sentence: our least liked fruit is the lemon , but my least liked is the grape .\n",
            "Decoded sentence: otre moins aimé fruit est la chaux , mais son moins aimé est la pomme ..tis est moins aimé est le citron ..t son mo\n",
            "-\n",
            "Input sentence: the united states is sometimes busy during january , and it is sometimes warm in november .\n",
            "Decoded sentence: es états-unis est parfois occupé en juin , mais il est parfois agréable en juin .t mais en été es pluves ..cit le c\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}